## Version 1
This is version 1 codes for the paper [**Quantifying Explainability of Saliency Methods in Deep Neural Networks**](https://arxiv.org/abs/2009.02899). 

Version 2 is now available. It includes streamlined version of codes in version 1 and a few additional functions.

Codes are in python, Deep learning models in pytorch.

Be sure to check out the tutorial folder to see how to use or display the dataset.

The main results in the paper are produced using 
```
python main.py --mode workflow --mode2 workflow1
python main.py --mode workflow --mode2 workflow2
python main.py --mode workflow --mode2 workflow3
```
Use python main.py to explore any other commands.


![](https://drive.google.com/uc?export=view&id=1GjHAn62ahfeBOaRoxcVMOwpMuQP7nFN2)
Fig. 1. Sample images from all 10 classes in 3 different types of background (row 1-3). The corresponding heatmaps are in row 4-6.

Existing results are available in the google drive <a href="https://drive.google.com/drive/folders/1fk9ABel49Vdlp4IcZsffgKoyM8rE110W?usp=sharing">link</a>.
